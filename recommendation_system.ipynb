{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cbd7356",
   "metadata": {},
   "source": [
    "# Anime Recommendation System: Introduction\n",
    "\n",
    "## Objective\n",
    "The goal of this project is to build a **recommendation system** that can suggest anime to users based on their past ratings and anime characteristics.\n",
    "\n",
    "## Dataset Overview\n",
    "We are using the [Anime Dataset](#https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database?select=rating.csv) containing:\n",
    "- **Anime information**: anime_id,name,genre,type,episodes,rating,members.\n",
    "- **User ratings**: user_id,anime_id,rating.\n",
    "\n",
    "## Project Goals\n",
    "1. Explore and preprocess the dataset to handle sparsity, missing values and noisy ratings.\n",
    "2. Implement multiple recommendation techniques:\n",
    "    - **Baseline recommendation**: Simple popularity-based recommendations.\n",
    "    - **Collaborative Filtering (CF)**: Suggest anime based on user-user or item-item similarity.\n",
    "    - **Content-Based Filtering (CBF)**: Recommend anime using genre, type, and other features.\n",
    "    - **Hybrid approaches**: Combine CF and CBF for better predictions.\n",
    "3. Evaluate model performance using metrics like **RMSE** and **MAE**.\n",
    "4. Visualise recommendations and analyze patterns in user preferences and anime clusters.\n",
    "\n",
    "## Why This Matters\n",
    "Recommendation systems help users **discover content they are likely to enjoy** and are a critical part of many modern applications. By combining user behavior and content features, I aim to build a system that can provide **personalized anime recommendations** and gain insights into anime clustering and user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63b61d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822fba6",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Before building any recommendation system, we need to **clean, preprocess and structure the data**. This involves:\n",
    "\n",
    "1. **Handling missing values**. \n",
    "2. **Filtering invalid ratings**.  \n",
    "4. **Creating a user-item rating matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c340345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime dataset: (12294, 7)\n",
      "Ratings dataset: (7813737, 3)\n",
      "Unique anime: 12294\n",
      "Unique users: 73515\n",
      "Total ratings: rating\n",
      " 8     1646019\n",
      "-1     1476496\n",
      " 7     1375287\n",
      " 9     1254096\n",
      " 10     955715\n",
      " 6      637775\n",
      " 5      282806\n",
      " 4      104291\n",
      " 3       41453\n",
      " 2       23150\n",
      " 1       16649\n",
      "Name: count, dtype: int64\n",
      "   anime_id                              name  \\\n",
      "0     32281                    Kimi no Na wa.   \n",
      "1      5114  Fullmetal Alchemist: Brotherhood   \n",
      "2     28977                          Gintama°   \n",
      "3      9253                       Steins;Gate   \n",
      "4      9969                     Gintama&#039;   \n",
      "\n",
      "                                               genre   type episodes  rating  \\\n",
      "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
      "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
      "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
      "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
      "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
      "\n",
      "   members  \n",
      "0   200630  \n",
      "1   793665  \n",
      "2   114262  \n",
      "3   673572  \n",
      "4   151266  \n",
      "   user_id  anime_id  rating\n",
      "0        1        20      -1\n",
      "1        1        24      -1\n",
      "2        1        79      -1\n",
      "3        1       226      -1\n",
      "4        1       241      -1\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets\n",
    "\n",
    "anime_df = pd.read_csv('data/anime.csv')\n",
    "ratings_df = pd.read_csv('data/rating.csv')\n",
    "\n",
    "print(f\"Anime dataset: {anime_df.shape}\")\n",
    "print(f\"Ratings dataset: {ratings_df.shape}\")\n",
    "\n",
    "# Displaying basic information\n",
    "\n",
    "print(f\"Unique anime: {anime_df['anime_id'].nunique()}\")\n",
    "print(f\"Unique users: {ratings_df['user_id'].nunique()}\")\n",
    "print(f\"Total ratings: {ratings_df['rating'].value_counts()}\")\n",
    "\n",
    "# Display data \n",
    "\n",
    "print(anime_df.head())\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af3f6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime entries after cleaning: 10931\n",
      "Ratings after cleaning: 6337241\n",
      "     user_id  anime_id  rating\n",
      "156        3        20       8\n",
      "157        3       154       6\n",
      "158        3       170       9\n",
      "159        3       199      10\n",
      "160        3       225       9\n",
      "Users: 60,970\n",
      "Items: 8,030\n",
      "Ratings: 6,314,650\n",
      "Sparsity: 98.71%\n",
      "Avg ratings per user: 103.6\n",
      "Avg ratings per item: 786.4\n"
     ]
    }
   ],
   "source": [
    "# Cleaning anime data\n",
    "\n",
    "anime_df['rating'] = pd.to_numeric(anime_df['rating'], errors='coerce')\n",
    "anime_df['episodes'] = pd.to_numeric(anime_df['episodes'], errors='coerce')\n",
    "anime_df['members'] = pd.to_numeric(anime_df['members'], errors='coerce')\n",
    "\n",
    "# removing all anime without ratings (-1) and adult content\n",
    "\n",
    "anime_clean = anime_df.dropna(subset=['rating'].copy())\n",
    "anime_clean = anime_clean[~anime_clean['genre'].str.contains('Hentai', case=False, na=False)].copy()\n",
    "print(f\"Anime entries after cleaning: {len(anime_clean)}\")\n",
    "\n",
    "# Cleaning rating data\n",
    "\n",
    "ratings_clean = ratings_df[(ratings_df['rating'] != -1) & (ratings_df['rating'].notna())].copy()\n",
    "print(f\"Ratings after cleaning: {len(ratings_clean)}\")\n",
    "\n",
    "# Removing all users and items with few interactions (deals with the sparcity)\n",
    "\n",
    "user_counts = ratings_clean['user_id'].value_counts()\n",
    "item_counts = ratings_clean['anime_id'].value_counts()\n",
    "\n",
    "# Keeping anime with at least 5 ratings\n",
    "\n",
    "min_user_ratings = 5\n",
    "min_item_ratings = 5\n",
    "\n",
    "valid_users = user_counts[user_counts >= min_user_ratings].index\n",
    "valid_items = item_counts[item_counts >= min_item_ratings].index\n",
    "\n",
    "ratings_filtered = ratings_clean[\n",
    "    (ratings_clean['user_id'].isin(valid_users)) & \n",
    "    (ratings_clean['anime_id'].isin(valid_items))\n",
    "].copy()\n",
    "\n",
    "print(ratings_filtered.head())\n",
    "# Calculating sparcity\n",
    "\n",
    "n_users = ratings_filtered['user_id'].nunique()\n",
    "n_items = ratings_filtered['anime_id'].nunique()\n",
    "n_ratings = len(ratings_filtered)\n",
    "sparsity = (1 - n_ratings / (n_users * n_items)) * 100\n",
    "\n",
    "print(f\"Users: {n_users:,}\")\n",
    "print(f\"Items: {n_items:,}\")\n",
    "print(f\"Ratings: {n_ratings:,}\")\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")\n",
    "print(f\"Avg ratings per user: {n_ratings/n_users:.1f}\")\n",
    "print(f\"Avg ratings per item: {n_ratings/n_items:.1f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da8015",
   "metadata": {},
   "source": [
    "## Popularity Baseline Recommender\n",
    "\n",
    "The first step in building our recommendation system, we implement a **popularity-based baseline**. This baseline recommends the most popular items to all users, ignoring personal preferences. \n",
    "\n",
    "### How it Works:\n",
    "1. **Fit Phase**:\n",
    "- Compute average rating and count for each item.\n",
    "- Filter items with too few ratings (to reduce noise).\n",
    "- Rank items by average rating to determine popularity.\n",
    "2. **Prediction**:\n",
    "- If the item exists in the popular list, return its average rating.\n",
    "- Otherwise, return the global average rating.\n",
    "3. **Recommendation**:\n",
    "- Return top-N popular items.\n",
    "- Optionally, exclude items the user has already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "432ca8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityBaseline:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.popular_items = None\n",
    "        self.global_mean = None\n",
    "\n",
    "    def fit(self, ratings_df):\n",
    "        # Learns the most popular anime from the data\n",
    "\n",
    "        # Calculate the popularity score\n",
    "\n",
    "        item_stats = ratings_df.groupby('anime_id').agg({'rating' : ['mean','count']}).round(3)\n",
    "        item_stats.columns = ['avg_rating','rating_count']\n",
    "\n",
    "        # Only get anime with more than 10 ratings\n",
    "\n",
    "        item_stats = item_stats[item_stats['rating_count'] >= 10]\n",
    "\n",
    "        # Sort the anime by their avg_rating\n",
    "        self.popular_items = item_stats.sort_values('avg_rating', ascending = False)\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "\n",
    "        print(f\"Baseline trained on {len(item_stats)} popular items\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        # Predicts the rating for a user-item pair\n",
    "        if self.popular_items is None:\n",
    "            return self.global_mean\n",
    "        \n",
    "        if item_id in self.popular_items.index:\n",
    "            return self.popular_items.loc[item_id, 'avg_rating']\n",
    "        else:\n",
    "            return self.global_mean\n",
    "        \n",
    "    def recommend(self, user_id, n_recommendations, exclude_seen = None):\n",
    "        # Recomend the top popular items\n",
    "\n",
    "        recommendations = self.popular_items.head(n_recommendations).index.tolist()\n",
    "\n",
    "        if exclude_seen:\n",
    "            # Get all the popular items which have not been seen by the user\n",
    "            recommendations = [item for item in recommendations if item not in exclude_seen]\n",
    "\n",
    "            remaining = n_recommendations - len(recommendations)\n",
    "            if remaining > 0:\n",
    "                additional = self.popular_items.iloc[n_recommendations:n_recommendations+remaining*2]\n",
    "                for item in additional.index:\n",
    "                    if item not in exclude_seen:\n",
    "                        recommendations.append(item)\n",
    "                        if len(recommendations) >= n_recommendations:\n",
    "                            break\n",
    "\n",
    "            return recommendations[:n_recommendations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a0b509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Popularity Baseline\n",
      "Baseline trained on 7364 popular items\n",
      " 1. Gintama°                                 | Rating: 9.45 |Count: 1,182\n",
      " 1. Kimi no Na wa.                           | Rating: 9.42 |Count: 1,948\n",
      " 1. Ginga Eiyuu Densetsu                     | Rating: 9.39 |Count: 799\n",
      " 1. Fullmetal Alchemist: Brotherhood         | Rating: 9.32 |Count: 21,220\n",
      " 1. Gintama&#039;                            | Rating: 9.27 |Count: 3,098\n",
      " 1. Steins;Gate                              | Rating: 9.26 |Count: 17,019\n",
      " 1. Hunter x Hunter (2011)                   | Rating: 9.23 |Count: 7,418\n",
      " 1. Gintama                                  | Rating: 9.23 |Count: 4,222\n",
      " 1. Gintama&#039;: Enchousen                 | Rating: 9.20 |Count: 2,121\n",
      " 1. Gintama Movie: Kanketsu-hen - Yorozuya y | Rating: 9.19 |Count: 2,139\n"
     ]
    }
   ],
   "source": [
    "# Train baseline model\n",
    "print(\"Training Popularity Baseline\")\n",
    "baseline_model = PopularityBaseline()\n",
    "baseline_model.fit(ratings_filtered)\n",
    "\n",
    "# Show the top recommendation\n",
    "\n",
    "top_anime_ids = baseline_model.popular_items.head(10).index\n",
    "for i, anime_id in enumerate(top_anime_ids, 1):\n",
    "    anime_name = anime_clean[anime_clean['anime_id'] == anime_id]['name'].iloc[0]\n",
    "    avg_rating = baseline_model.popular_items.loc[anime_id, 'avg_rating']\n",
    "    rating_count = baseline_model.popular_items.loc[anime_id, 'rating_count']\n",
    "    print(f'{1:2d}. {anime_name[:40]:40} | Rating: {avg_rating:.2f} |Count: {rating_count:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c01b80f",
   "metadata": {},
   "source": [
    "# Content-Based Filtering for Anime Recommendations\n",
    "\n",
    "This section implements a **content-based recommendation system** that leverages **anime features** to generate personalised recommendations.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Feature Preparation**\n",
    "   - Genre features transformed using **TF-IDF**.\n",
    "   - Anime type features encoded as **one-hot vectors**.\n",
    "   - Numeric features like `rating`, `episodes`, and `members` **normalised**.\n",
    "   - Combined all features into a **single feature matrix**.\n",
    "\n",
    "2. **Similarity Computation**\n",
    "   - Compute **cosine similarity** between all anime.\n",
    "   - Store similarity matrix.\n",
    "\n",
    "3. **Personalized Recommendation**\n",
    "   - For each anime a user has rated, retrieve similar anime.\n",
    "   - Weight similarity scores by the user’s rating.\n",
    "   - Aggregate scores and sort to recommend the top-N anime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedFilter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.item_features = None\n",
    "        self.item_similarity_matrix = None\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.anime_to_idx = None\n",
    "        self.idx_to_anime = None\n",
    "\n",
    "    def prepare_features(self, anime_df):\n",
    "        # preparing the feature matrix for anime\n",
    "\n",
    "\n",
    "        anime_ids = anime_df['anime_id'].values\n",
    "        self.anime_to_idx = {anime_id: idx for idx, anime_id in enumerate(anime_id)}\n",
    "        self.idx_to_anime = {idx : anime_id for anime_id, idx in self.anime_to_idx.items()}\n",
    "\n",
    "        features_list = []\n",
    "\n",
    "        # Genres features using TF-IDF\n",
    "\n",
    "        genres = anime_df['genre'].fillna('Unknown')\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(max_features=50, stop_words=None)\n",
    "        genre_features = self.tfidf_vectorizer.fit_transform(genres)\n",
    "        features_list.append(genre_features)\n",
    "\n",
    "        # Type features\n",
    "\n",
    "        type_dummies = pd.get_dummies(anime_df['type']).values\n",
    "        features_list.append(type_dummies)\n",
    "\n",
    "        # Numerical features (normalised)\n",
    "\n",
    "        numerical_features = anime_df[['rating', 'episodes', 'members']].copy()\n",
    "        numerical_features['episodes'] = numerical_features['episodes'].fillna(1)\n",
    "\n",
    "        # normalise numerical features \n",
    "        for col in numerical_features.columns:\n",
    "            numerical_features[col] = (numerical_features[col] - numerical_features[col].mean()) / numerical_features[col].std()\n",
    "\n",
    "        features_list.append(numerical_features.value)\n",
    "\n",
    "        # Combine all features\n",
    "\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
